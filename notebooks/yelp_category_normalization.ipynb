{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c60cf2",
   "metadata": {},
   "source": [
    "# Yelp Category Normalization\n",
    "This step will be extracting the category string from the yelp data and grouping them by traditional K-means clustering so that it is an easier list to work with.\n",
    "\n",
    "This data is then stored into a new field on the JSON, 'normal_category' for future methodologies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37fbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Load Data from JSON\n",
    "data = []\n",
    "with open('../data/processed/yelp_cleaned.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Drop businesses without categories, as we will be clustering based on these\n",
    "df = df.dropna(subset=['categories'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58c017",
   "metadata": {},
   "source": [
    "## TF-IDF Usage\n",
    "\n",
    "We use TF-IDF (Term Frequency and Inverse Document Frequency) to assign a numerical value that combines uniqueness of words and their frequencies to allow them to be clustered just as numerical values would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0201d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Tfidf to turn strings into numerical features\n",
    "# we use max_features to keep the matrix manageable\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(df['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171b157",
   "metadata": {},
   "source": [
    "## Actual Clustering\n",
    "\n",
    "Now we can do the actual clustering logic to find the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cbfa257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\austi\\anaconda3\\envs\\CS4630Proj1\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Examples\n",
      "\n",
      "CLUSTER 0:\n",
      "  Sample 1: fashion, shopping, department stores, furniture stores, candle stores, home & garden, home decor\n",
      "  Sample 2: shopping, auction houses, active life\n",
      "\n",
      "CLUSTER 1:\n",
      "  Sample 1: health & medical, beauty & spas, laser hair removal, doctors, hair removal, chiropractors, weight loss centers, sports medicine, medical spas, skin care\n",
      "  Sample 2: ophthalmologists, eyewear & opticians, health & medical, shopping, doctors, optometrists\n",
      "\n",
      "CLUSTER 2:\n",
      "  Sample 1: korean, restaurants\n",
      "  Sample 2: restaurants, italian\n",
      "\n",
      "CLUSTER 3:\n",
      "  Sample 1: eatertainment, arts & entertainment, brewpubs, american (traditional), bakeries, breweries, food, restaurants\n",
      "  Sample 2: food, grocery\n",
      "\n",
      "CLUSTER 4:\n",
      "  Sample 1: pizza, restaurants, salad, soup\n",
      "  Sample 2: pizza, restaurants\n",
      "\n",
      "CLUSTER 5:\n",
      "  Sample 1: dui law, professional services, lawyers, criminal defense law\n",
      "  Sample 2: keys & locksmiths, home services, local services\n",
      "\n",
      "CLUSTER 6:\n",
      "  Sample 1: car wash, auto detailing, automotive\n",
      "  Sample 2: gas stations, automotive, towing\n",
      "\n",
      "CLUSTER 7:\n",
      "  Sample 1: restaurants, food, bubble tea, coffee & tea, bakeries\n",
      "  Sample 2: restaurants, automotive, delis, gas stations, food, coffee & tea, sandwiches, convenience stores\n",
      "\n",
      "CLUSTER 8:\n",
      "  Sample 1: barbers, beauty & spas\n",
      "  Sample 2: beauty & spas, hair stylists, hair extensions, hair salons\n",
      "\n",
      "CLUSTER 9:\n",
      "  Sample 1: sushi bars, restaurants, japanese\n",
      "  Sample 2: cocktail bars, bars, italian, nightlife, restaurants\n"
     ]
    }
   ],
   "source": [
    "k_val = 10 # Number of categories we want to end with\n",
    "model = KMeans(n_clusters=k_val, init='k-means++', max_iter=500, n_init=10)\n",
    "df['cluster'] = model.fit_predict(X)\n",
    "\n",
    "# This will print the first two results in each cluster so that we can see examples of what the clusters found\n",
    "print(\"Cluster Examples\")\n",
    "for i in range(k_val):\n",
    "    print(f\"\\nCLUSTER {i}:\")\n",
    "    samples = df[df['cluster'] == i]['categories'].head(2).tolist()\n",
    "    \n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"  Sample {j+1}: {sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd88c1",
   "metadata": {},
   "source": [
    "## Name Clusters\n",
    "Next, we want to use the most common words in each centroid to come up with a suitable name for that cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcf45de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0, 2434 items, category: shopping & stores & fashion\n",
      "Cluster 1, 1673 items, category: medical & health & dentists\n",
      "Cluster 2, 3471 items, category: restaurants & chinese & american\n",
      "Cluster 3, 3031 items, category: food & restaurants & grocery\n",
      "Cluster 4, 1054 items, category: pizza & restaurants & italian\n",
      "Cluster 5, 5615 items, category: services & home & local\n",
      "Cluster 6, 1187 items, category: automotive & auto & repair\n",
      "Cluster 7, 1219 items, category: tea & coffee & food\n",
      "Cluster 8, 1845 items, category: spas & beauty & salons\n",
      "Cluster 9, 1870 items, category: bars & nightlife & restaurants\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "# make sure centroids are in numerical order\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "\n",
    "cluster_names = {}\n",
    "for i in range(k_val):\n",
    "    # Get the top 3 most significant words for this cluster\n",
    "    top_words = [terms[ind] for ind in order_centroids[i, :3]]\n",
    "    cluster_names[i] = \" & \".join(top_words)\n",
    "    print(f\"Cluster {i}, {cluster_counts.get(i, 0)} items, category: {cluster_names[i]}\")\n",
    "\n",
    "# Map names back to the dataframe in a new 'normal_category' field\n",
    "df['normal_category'] = df['cluster'].map(cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a9b25",
   "metadata": {},
   "source": [
    "## Return Processed Data\n",
    "\n",
    "We can use these new categories and return back the json values into our processed folder for further integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf77b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export complete at: ../data/processed/yelp_clustered_categories.json\n"
     ]
    }
   ],
   "source": [
    "outputLoc = '../data/processed/yelp_clustered_categories.json'\n",
    "\n",
    "# Save each row as a separate JSON object on its own line like yelp had originally\n",
    "df.to_json(outputLoc, orient='records', lines=True)\n",
    "\n",
    "print(f'Export complete at: {outputLoc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4630Proj1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
