{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c60cf2",
   "metadata": {},
   "source": [
    "# Yelp Category Normalization\n",
    "This step will be extracting the category string from the yelp data and grouping them by traditional K-means clustering so that it is an easier list to work with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37fbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Load Data from JSON\n",
    "data = []\n",
    "with open('../data/raw/yelp_academic_dataset_business.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Drop businesses without categories, as we will be clustering based on these\n",
    "df = df.dropna(subset=['categories'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0201d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Tfidf to turn strings into numerical features\n",
    "# we use max_features to keep the matrix manageable\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(df['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171b157",
   "metadata": {},
   "source": [
    "## Actual Clustering\n",
    "\n",
    "Now we can do the actual clustering logic to find the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbfa257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Examples\n",
      "\n",
      "CLUSTER 0:\n",
      "  Sample 1: Pubs, Restaurants, Italian, Bars, American (Traditional), Nightlife, Greek\n",
      "  Sample 2: Sushi Bars, Restaurants, Japanese\n",
      "\n",
      "CLUSTER 1:\n",
      "  Sample 1: Shipping Centers, Local Services, Notaries, Mailbox Centers, Printing Services\n",
      "  Sample 2: Sporting Goods, Fashion, Shoe Stores, Shopping, Sports Wear, Accessories\n",
      "\n",
      "CLUSTER 2:\n",
      "  Sample 1: Hair Salons, Hair Extensions, Beauty & Spas, Wigs, Shopping\n",
      "  Sample 2: Health & Medical, Personal Care Services, Beauty & Spas, Massage, Nail Salons\n",
      "\n",
      "CLUSTER 3:\n",
      "  Sample 1: Doctors, Traditional Chinese Medicine, Naturopathic/Holistic, Acupuncture, Health & Medical, Nutritionists\n",
      "  Sample 2: General Dentistry, Dentists, Health & Medical, Cosmetic Dentists\n",
      "\n",
      "CLUSTER 4:\n",
      "  Sample 1: Automotive, Car Rental, Hotels & Travel, Truck Rental\n",
      "  Sample 2: Event Planning & Services, Hotels, Hotels & Travel\n",
      "\n",
      "CLUSTER 5:\n",
      "  Sample 1: Korean, Restaurants\n",
      "  Sample 2: Steakhouses, Asian Fusion, Restaurants\n",
      "\n",
      "CLUSTER 6:\n",
      "  Sample 1: Restaurants, Food, Bubble Tea, Coffee & Tea, Bakeries\n",
      "  Sample 2: Brewpubs, Breweries, Food\n",
      "\n",
      "CLUSTER 7:\n",
      "  Sample 1: Automotive, Auto Parts & Supplies, Auto Customization\n",
      "  Sample 2: Towing, Automotive, Body Shops\n",
      "\n",
      "CLUSTER 8:\n",
      "  Sample 1: Department Stores, Shopping, Fashion, Home & Garden, Electronics, Furniture Stores\n",
      "  Sample 2: Fashion, Shopping, Department Stores, Furniture Stores, Candle Stores, Home & Garden, Home Decor\n",
      "\n",
      "CLUSTER 9:\n",
      "  Sample 1: American (Traditional), Restaurants, Diners, Breakfast & Brunch\n",
      "  Sample 2: Eatertainment, Arts & Entertainment, Brewpubs, American (Traditional), Bakeries, Breweries, Food, Restaurants\n"
     ]
    }
   ],
   "source": [
    "k_val = 10 # Number of categories we want to end with\n",
    "model = KMeans(n_clusters=k_val, init='k-means++', max_iter=200, n_init=10)\n",
    "df['cluster'] = model.fit_predict(X)\n",
    "\n",
    "# This will print the first two results in each cluster so that we can see examples of what the clusters found\n",
    "print(\"Cluster Examples\")\n",
    "for i in range(k_val):\n",
    "    print(f\"\\nCLUSTER {i}:\")\n",
    "    samples = df[df['cluster'] == i]['categories'].head(2).tolist()\n",
    "    \n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"  Sample {j+1}: {sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd88c1",
   "metadata": {},
   "source": [
    "## Name Clusters\n",
    "Next, we want to use the most common words in each centroid to come up with a suitable name for that cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcf45de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0, 11294 items, category: bars & nightlife & restaurants\n",
      "Cluster 1, 32736 items, category: shopping & services & pet\n",
      "Cluster 2, 11438 items, category: spas & beauty & salons\n",
      "Cluster 3, 10846 items, category: medical & health & dentists\n",
      "Cluster 4, 8785 items, category: event & hotels & planning\n",
      "Cluster 5, 18238 items, category: restaurants & pizza & italian\n",
      "Cluster 6, 23859 items, category: food & restaurants & tea\n",
      "Cluster 7, 8881 items, category: automotive & auto & repair\n",
      "Cluster 8, 16588 items, category: home & services & estate\n",
      "Cluster 9, 7578 items, category: american & traditional & restaurants\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "# make sure centroids are in numerical order\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "\n",
    "cluster_names = {}\n",
    "for i in range(k_val):\n",
    "    # Get the top 3 most significant words for this cluster\n",
    "    top_words = [terms[ind] for ind in order_centroids[i, :3]]\n",
    "    cluster_names[i] = \" & \".join(top_words)\n",
    "    print(f\"Cluster {i}, {cluster_counts.get(i, 0)} items, category: {cluster_names[i]}\")\n",
    "\n",
    "# Map names back to the dataframe in a new 'normal_category' field\n",
    "df['normal_category'] = df['cluster'].map(cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a9b25",
   "metadata": {},
   "source": [
    "## Return Processed Data\n",
    "\n",
    "We can use these new categories and return back the json values into our processed folder for further integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf77b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export complete at: ../data/processed/yelp_clustered_categories.json\n"
     ]
    }
   ],
   "source": [
    "outputLoc = '../data/processed/yelp_clustered_categories.json'\n",
    "\n",
    "# Save each row as a separate JSON object on its own line like yelp had originally\n",
    "df.to_json(outputLoc, orient='records', lines=True)\n",
    "\n",
    "print(f'Export complete at: {outputLoc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
