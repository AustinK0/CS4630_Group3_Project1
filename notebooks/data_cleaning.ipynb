{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9e9256",
   "metadata": {},
   "source": [
    "# NYC 311 Data Cleaning Pipeline\n",
    "This notebook implements comprehensive data cleaning for the NYC 311 Service Requests dataset including:\n",
    "- Missing value handling\n",
    "- Deduplication\n",
    "- Column standardization\n",
    "- Data type conversion\n",
    "- Location validation\n",
    "- Text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "691d083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a2745",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bb119a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13262, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Key</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Closed Date</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Name</th>\n",
       "      <th>Problem (formerly Complaint Type)</th>\n",
       "      <th>Problem Detail (formerly Descriptor)</th>\n",
       "      <th>Additional Details</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Incident Zip</th>\n",
       "      <th>...</th>\n",
       "      <th>Vehicle Type</th>\n",
       "      <th>Taxi Company Borough</th>\n",
       "      <th>Taxi Pick Up Location</th>\n",
       "      <th>Bridge Highway Name</th>\n",
       "      <th>Bridge Highway Direction</th>\n",
       "      <th>Road Ramp</th>\n",
       "      <th>Bridge Highway Segment</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67869470</td>\n",
       "      <td>02/06/2026 02:05:09 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.616645</td>\n",
       "      <td>-73.992191</td>\n",
       "      <td>POINT (-73.992190975602 40.616645363723)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67858781</td>\n",
       "      <td>02/06/2026 02:04:35 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.858560</td>\n",
       "      <td>-73.929669</td>\n",
       "      <td>POINT (-73.929669194282 40.858560221857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67860301</td>\n",
       "      <td>02/06/2026 02:04:28 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11355.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.752019</td>\n",
       "      <td>-73.821211</td>\n",
       "      <td>POINT (-73.821211164678 40.752018968731)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67858763</td>\n",
       "      <td>02/06/2026 02:02:03 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>Blocked Hydrant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.738983</td>\n",
       "      <td>-73.899837</td>\n",
       "      <td>POINT (-73.899837120308 40.738983283506)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67861825</td>\n",
       "      <td>02/06/2026 02:01:27 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>Loud Talking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11693.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.604511</td>\n",
       "      <td>-73.820936</td>\n",
       "      <td>POINT (-73.820936340811 40.604511386258)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique Key            Created Date Closed Date Agency  \\\n",
       "0    67869470  02/06/2026 02:05:09 AM         NaN   NYPD   \n",
       "1    67858781  02/06/2026 02:04:35 AM         NaN   NYPD   \n",
       "2    67860301  02/06/2026 02:04:28 AM         NaN   NYPD   \n",
       "3    67858763  02/06/2026 02:02:03 AM         NaN   NYPD   \n",
       "4    67861825  02/06/2026 02:01:27 AM         NaN   NYPD   \n",
       "\n",
       "                       Agency Name Problem (formerly Complaint Type)  \\\n",
       "0  New York City Police Department               Noise - Residential   \n",
       "1  New York City Police Department               Noise - Residential   \n",
       "2  New York City Police Department               Noise - Residential   \n",
       "3  New York City Police Department                   Illegal Parking   \n",
       "4  New York City Police Department           Noise - Street/Sidewalk   \n",
       "\n",
       "  Problem Detail (formerly Descriptor) Additional Details  \\\n",
       "0                     Banging/Pounding                NaN   \n",
       "1                     Banging/Pounding                NaN   \n",
       "2                     Banging/Pounding                NaN   \n",
       "3                      Blocked Hydrant                NaN   \n",
       "4                         Loud Talking                NaN   \n",
       "\n",
       "                Location Type  Incident Zip  ... Vehicle Type  \\\n",
       "0  Residential Building/House       11204.0  ...          NaN   \n",
       "1  Residential Building/House       10040.0  ...          NaN   \n",
       "2  Residential Building/House       11355.0  ...          NaN   \n",
       "3             Street/Sidewalk       11377.0  ...          NaN   \n",
       "4             Street/Sidewalk       11693.0  ...          NaN   \n",
       "\n",
       "  Taxi Company Borough Taxi Pick Up Location Bridge Highway Name  \\\n",
       "0                  NaN                   NaN                 NaN   \n",
       "1                  NaN                   NaN                 NaN   \n",
       "2                  NaN                   NaN                 NaN   \n",
       "3                  NaN                   NaN                 NaN   \n",
       "4                  NaN                   NaN                 NaN   \n",
       "\n",
       "  Bridge Highway Direction Road Ramp Bridge Highway Segment   Latitude  \\\n",
       "0                      NaN       NaN                    NaN  40.616645   \n",
       "1                      NaN       NaN                    NaN  40.858560   \n",
       "2                      NaN       NaN                    NaN  40.752019   \n",
       "3                      NaN       NaN                    NaN  40.738983   \n",
       "4                      NaN       NaN                    NaN  40.604511   \n",
       "\n",
       "   Longitude                                  Location  \n",
       "0 -73.992191  POINT (-73.992190975602 40.616645363723)  \n",
       "1 -73.929669  POINT (-73.929669194282 40.858560221857)  \n",
       "2 -73.821211  POINT (-73.821211164678 40.752018968731)  \n",
       "3 -73.899837  POINT (-73.899837120308 40.738983283506)  \n",
       "4 -73.820936  POINT (-73.820936340811 40.604511386258)  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load NYC 311 data\n",
    "# Note: Using on_bad_lines='skip' to handle malformed rows in the CSV\n",
    "df = pd.read_csv(\"../data/raw/nyc_311/nyc_311_raw.csv\", \n",
    "                  on_bad_lines='skip',\n",
    "                  engine='python')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88283881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "                                      Missing Count  Percentage\n",
      "Facility Type                                 13259   99.977379\n",
      "Taxi Company Borough                          13244   99.864274\n",
      "Due Date                                      13243   99.856734\n",
      "Bridge Highway Direction                      13237   99.811491\n",
      "Road Ramp                                     13236   99.803951\n",
      "Bridge Highway Name                           13220   99.683306\n",
      "Bridge Highway Segment                        13220   99.683306\n",
      "Taxi Pick Up Location                         13153   99.178103\n",
      "Vehicle Type                                  12761   96.222289\n",
      "Closed Date                                    7316   55.165133\n",
      "Landmark                                       6745   50.859599\n",
      "Additional Details                             6460   48.710602\n",
      "Intersection Street 2                          5868   44.246720\n",
      "Intersection Street 1                          5865   44.224099\n",
      "Cross Street 2                                 5447   41.072236\n",
      "Cross Street 1                                 5439   41.011914\n",
      "Resolution Description                         2435   18.360730\n",
      "Resolution Action Updated Date                 2383   17.968632\n",
      "Location Type                                  1431   10.790228\n",
      "BBL                                            1291    9.734580\n",
      "City                                            604    4.554366\n",
      "Street Name                                     396    2.985975\n",
      "Incident Address                                395    2.978435\n",
      "Council District                                182    1.372342\n",
      "X Coordinate (State Plane)                      144    1.085809\n",
      "Latitude                                        144    1.085809\n",
      "Longitude                                       144    1.085809\n",
      "Y Coordinate (State Plane)                      144    1.085809\n",
      "Location                                        144    1.085809\n",
      "Incident Zip                                     71    0.535364\n",
      "Problem Detail (formerly Descriptor)             56    0.422259\n",
      "Address Type                                     48    0.361936\n",
      "\n",
      "Total missing values: 171725\n",
      "Density: 29.43%\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing Count': missing_values, 'Percentage': missing_percent})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Percentage', ascending=False)\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(missing_df)\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Density: {df.isnull().sum().sum() / (len(df) * len(df.columns)):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f057e9",
   "metadata": {},
   "source": [
    "## Standardize Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4ddf75ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13262, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>problem_formerly_complaint_type</th>\n",
       "      <th>problem_detail_formerly_descriptor</th>\n",
       "      <th>additional_details</th>\n",
       "      <th>location_type</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>taxi_company_borough</th>\n",
       "      <th>taxi_pick_up_location</th>\n",
       "      <th>bridge_highway_name</th>\n",
       "      <th>bridge_highway_direction</th>\n",
       "      <th>road_ramp</th>\n",
       "      <th>bridge_highway_segment</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67869470</td>\n",
       "      <td>02/06/2026 02:05:09 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.616645</td>\n",
       "      <td>-73.992191</td>\n",
       "      <td>POINT (-73.992190975602 40.616645363723)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67858781</td>\n",
       "      <td>02/06/2026 02:04:35 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.858560</td>\n",
       "      <td>-73.929669</td>\n",
       "      <td>POINT (-73.929669194282 40.858560221857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67860301</td>\n",
       "      <td>02/06/2026 02:04:28 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11355.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.752019</td>\n",
       "      <td>-73.821211</td>\n",
       "      <td>POINT (-73.821211164678 40.752018968731)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67858763</td>\n",
       "      <td>02/06/2026 02:02:03 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>Blocked Hydrant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.738983</td>\n",
       "      <td>-73.899837</td>\n",
       "      <td>POINT (-73.899837120308 40.738983283506)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67861825</td>\n",
       "      <td>02/06/2026 02:01:27 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>Loud Talking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11693.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.604511</td>\n",
       "      <td>-73.820936</td>\n",
       "      <td>POINT (-73.820936340811 40.604511386258)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key            created_date closed_date agency  \\\n",
       "0    67869470  02/06/2026 02:05:09 AM         NaN   NYPD   \n",
       "1    67858781  02/06/2026 02:04:35 AM         NaN   NYPD   \n",
       "2    67860301  02/06/2026 02:04:28 AM         NaN   NYPD   \n",
       "3    67858763  02/06/2026 02:02:03 AM         NaN   NYPD   \n",
       "4    67861825  02/06/2026 02:01:27 AM         NaN   NYPD   \n",
       "\n",
       "                       agency_name problem_formerly_complaint_type  \\\n",
       "0  New York City Police Department             Noise - Residential   \n",
       "1  New York City Police Department             Noise - Residential   \n",
       "2  New York City Police Department             Noise - Residential   \n",
       "3  New York City Police Department                 Illegal Parking   \n",
       "4  New York City Police Department         Noise - Street/Sidewalk   \n",
       "\n",
       "  problem_detail_formerly_descriptor additional_details  \\\n",
       "0                   Banging/Pounding                NaN   \n",
       "1                   Banging/Pounding                NaN   \n",
       "2                   Banging/Pounding                NaN   \n",
       "3                    Blocked Hydrant                NaN   \n",
       "4                       Loud Talking                NaN   \n",
       "\n",
       "                location_type  incident_zip  ... vehicle_type  \\\n",
       "0  Residential Building/House       11204.0  ...          NaN   \n",
       "1  Residential Building/House       10040.0  ...          NaN   \n",
       "2  Residential Building/House       11355.0  ...          NaN   \n",
       "3             Street/Sidewalk       11377.0  ...          NaN   \n",
       "4             Street/Sidewalk       11693.0  ...          NaN   \n",
       "\n",
       "  taxi_company_borough taxi_pick_up_location bridge_highway_name  \\\n",
       "0                  NaN                   NaN                 NaN   \n",
       "1                  NaN                   NaN                 NaN   \n",
       "2                  NaN                   NaN                 NaN   \n",
       "3                  NaN                   NaN                 NaN   \n",
       "4                  NaN                   NaN                 NaN   \n",
       "\n",
       "  bridge_highway_direction road_ramp bridge_highway_segment   latitude  \\\n",
       "0                      NaN       NaN                    NaN  40.616645   \n",
       "1                      NaN       NaN                    NaN  40.858560   \n",
       "2                      NaN       NaN                    NaN  40.752019   \n",
       "3                      NaN       NaN                    NaN  40.738983   \n",
       "4                      NaN       NaN                    NaN  40.604511   \n",
       "\n",
       "   longitude                                  location  \n",
       "0 -73.992191  POINT (-73.992190975602 40.616645363723)  \n",
       "1 -73.929669  POINT (-73.929669194282 40.858560221857)  \n",
       "2 -73.821211  POINT (-73.821211164678 40.752018968731)  \n",
       "3 -73.899837  POINT (-73.899837120308 40.738983283506)  \n",
       "4 -73.820936  POINT (-73.820936340811 40.604511386258)  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize column names: lowercase, replace spaces with underscores, remove special chars\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"[^\\w_]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f4ad8",
   "metadata": {},
   "source": [
    "## Select relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "021dc7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13262, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>problem_formerly_complaint_type</th>\n",
       "      <th>problem_detail_formerly_descriptor</th>\n",
       "      <th>borough</th>\n",
       "      <th>agency</th>\n",
       "      <th>location_type</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67869470</td>\n",
       "      <td>02/06/2026 02:05:09 AM</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>40.616645</td>\n",
       "      <td>-73.992191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67858781</td>\n",
       "      <td>02/06/2026 02:04:35 AM</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>40.858560</td>\n",
       "      <td>-73.929669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67860301</td>\n",
       "      <td>02/06/2026 02:04:28 AM</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11355.0</td>\n",
       "      <td>40.752019</td>\n",
       "      <td>-73.821211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67858763</td>\n",
       "      <td>02/06/2026 02:02:03 AM</td>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>Blocked Hydrant</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11377.0</td>\n",
       "      <td>40.738983</td>\n",
       "      <td>-73.899837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67861825</td>\n",
       "      <td>02/06/2026 02:01:27 AM</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>Loud Talking</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11693.0</td>\n",
       "      <td>40.604511</td>\n",
       "      <td>-73.820936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key            created_date problem_formerly_complaint_type  \\\n",
       "0    67869470  02/06/2026 02:05:09 AM             Noise - Residential   \n",
       "1    67858781  02/06/2026 02:04:35 AM             Noise - Residential   \n",
       "2    67860301  02/06/2026 02:04:28 AM             Noise - Residential   \n",
       "3    67858763  02/06/2026 02:02:03 AM                 Illegal Parking   \n",
       "4    67861825  02/06/2026 02:01:27 AM         Noise - Street/Sidewalk   \n",
       "\n",
       "  problem_detail_formerly_descriptor    borough agency  \\\n",
       "0                   Banging/Pounding   BROOKLYN   NYPD   \n",
       "1                   Banging/Pounding  MANHATTAN   NYPD   \n",
       "2                   Banging/Pounding     QUEENS   NYPD   \n",
       "3                    Blocked Hydrant     QUEENS   NYPD   \n",
       "4                       Loud Talking     QUEENS   NYPD   \n",
       "\n",
       "                location_type  incident_zip   latitude  longitude  \n",
       "0  Residential Building/House       11204.0  40.616645 -73.992191  \n",
       "1  Residential Building/House       10040.0  40.858560 -73.929669  \n",
       "2  Residential Building/House       11355.0  40.752019 -73.821211  \n",
       "3             Street/Sidewalk       11377.0  40.738983 -73.899837  \n",
       "4             Street/Sidewalk       11693.0  40.604511 -73.820936  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select relevant columns (use standardized names; handle legacy variants)\n",
    "# Rename legacy column names if present\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"problem_formerly_complaint_type\",\n",
    "    \"problem_detail_formerly_descriptor\",\n",
    "    \"borough\",\n",
    "    \"agency\",\n",
    "    \"location_type\",\n",
    "    \"incident_zip\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "]\n",
    "\n",
    "# Keep only existing columns to avoid KeyError\n",
    "available_cols = [c for c in columns_to_keep if c in df.columns]\n",
    "missing_cols = [c for c in columns_to_keep if c not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: these expected columns not found and will be skipped: {missing_cols}\")\n",
    "\n",
    "if not available_cols:\n",
    "    raise ValueError(\"No expected columns found in dataframe. Check column names first.\")\n",
    "\n",
    "df = df[available_cols].copy()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfdceb",
   "metadata": {},
   "source": [
    "Summarized conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6d593",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8f4ebe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows after missing value handling: 13118\n",
      "\n",
      "Missing values after cleaning:\n",
      "incident_zip    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Strategy for handling missing values:\n",
    "# 1. Drop rows where unique_key (identifier) is missing (only if column exists)\n",
    "if 'unique_key' in df.columns:\n",
    "    df = df.dropna(subset=['unique_key'])\n",
    "else:\n",
    "    print(\"Warning: unique_key column not found in selected columns. Skipping unique_key validation.\")\n",
    "\n",
    "# 2. Fill text columns with 'Unknown'\n",
    "text_cols = ['problem_formerly_complaint_type', 'problem_detail_formerly_descriptor', \n",
    "             'additional_details', 'location_type', 'incident_address', 'city', 'borough']\n",
    "for col in text_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# 3. For latitude/longitude, drop rows with missing coordinates (critical for geospatial analysis)\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# 4. Drop rows with missing created_date\n",
    "if 'created_date' in df.columns:\n",
    "    df = df.dropna(subset=['created_date'])\n",
    "\n",
    "# 5. Fill other numeric/categorical columns appropriately\n",
    "if 'police_precinct' in df.columns:\n",
    "    df['police_precinct'] = df['police_precinct'].fillna('Unspecified')\n",
    "if 'community_board' in df.columns:\n",
    "    df['community_board'] = df['community_board'].fillna('Unspecified')\n",
    "\n",
    "print(f\"Remaining rows after missing value handling: {len(df)}\")\n",
    "print(f\"\\nMissing values after cleaning:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343a61d",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "993576a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed (exact duplicates): 0\n",
      "\n",
      "Remaining rows after deduplication: 13118\n",
      "Unique complaint keys: 13118\n"
     ]
    }
   ],
   "source": [
    "# Remove exact duplicates based on unique_key (if available)\n",
    "initial_rows = len(df)\n",
    "\n",
    "if 'unique_key' in df.columns:\n",
    "    df = df.drop_duplicates(subset=['unique_key'], keep='first')\n",
    "    exact_dupes = initial_rows - len(df)\n",
    "    print(f\"Rows removed (exact duplicates): {exact_dupes}\")\n",
    "else:\n",
    "    print(\"Warning: unique_key column not found. Skipping exact duplicate removal.\")\n",
    "    exact_dupes = 0\n",
    "\n",
    "# Check for near-duplicates (same complaint at same location within short time)\n",
    "# Sort by location and created date to identify potential duplicates\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns and 'created_date' in df.columns:\n",
    "    df_sorted = df.sort_values(['latitude', 'longitude', 'created_date'])\n",
    "    print(f\"\\nRemaining rows after deduplication: {len(df)}\")\n",
    "else:\n",
    "    print(\"\\nWarning: Required columns (latitude, longitude, created_date) not all present. Skipping near-duplicate detection.\")\n",
    "    \n",
    "if 'unique_key' in df.columns:\n",
    "    print(f\"Unique complaint keys: {df['unique_key'].nunique()}\")\n",
    "else:\n",
    "    print(\"Note: unique_key column unavailable for counting unique keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33754f5",
   "metadata": {},
   "source": [
    "## Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cb2ec683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      "unique_key                                     int64\n",
      "created_date                          datetime64[us]\n",
      "problem_formerly_complaint_type             category\n",
      "problem_detail_formerly_descriptor               str\n",
      "borough                                     category\n",
      "agency                                      category\n",
      "location_type                               category\n",
      "incident_zip                                 float64\n",
      "latitude                                     float64\n",
      "longitude                                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "date_cols = ['created_date', 'closed_date', 'due_date', 'resolution_action_updated_date']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Convert numeric columns\n",
    "numeric_cols = ['latitude', 'longitude', 'x_coordinate_state_plane', 'y_coordinate_state_plane']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Convert string columns to categorical for memory efficiency\n",
    "categorical_cols = ['agency', 'agency_name', 'problem_formerly_complaint_type', \n",
    "                    'location_type', 'status', 'borough', 'city']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "print(\"Data types after conversion:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb056529",
   "metadata": {},
   "source": [
    "## Location Validation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9a3a54c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with invalid coordinates: 62\n",
      "\n",
      "Rows after location validation: 13036\n",
      "Unique boroughs: 5\n",
      "borough\n",
      "BROOKLYN         4106\n",
      "QUEENS           3047\n",
      "BRONX            2947\n",
      "MANHATTAN        2452\n",
      "STATEN ISLAND     484\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Validate NYC coordinates (bounding box)\n",
    "# NYC latitude range: approximately 40.5 to 40.9\n",
    "# NYC longitude range: approximately -74.3 to -73.7\n",
    "invalid_coords = (\n",
    "    (df['latitude'] < 40.5) | (df['latitude'] > 40.9) |\n",
    "    (df['longitude'] < -74.3) | (df['longitude'] > -73.7)\n",
    ")\n",
    "print(f\"Rows with invalid coordinates: {invalid_coords.sum()}\")\n",
    "\n",
    "# Drop rows with invalid coordinates\n",
    "df = df[~invalid_coords].copy()\n",
    "\n",
    "# Clean ZIP codes: ensure 5-digit format\n",
    "if 'incident_zip' in df.columns:\n",
    "    df['incident_zip'] = df['incident_zip'].astype(str).str.extract('(\\d{5})', expand=False)\n",
    "    df = df[df['incident_zip'].notna()]\n",
    "\n",
    "# Normalize borough names\n",
    "if 'borough' in df.columns:\n",
    "    df['borough'] = df['borough'].str.upper().str.strip()\n",
    "    borough_mapping = {\n",
    "        'NY': 'MANHATTAN',\n",
    "        'NEWYORK': 'MANHATTAN',\n",
    "        'KINGS': 'BROOKLYN',\n",
    "        'QUEENS': 'QUEENS',\n",
    "        'BRONX': 'BRONX',\n",
    "        'RICHMOND': 'STATEN ISLAND'\n",
    "    }\n",
    "    for old, new in borough_mapping.items():\n",
    "        df['borough'] = df['borough'].replace(old, new)\n",
    "\n",
    "print(f\"\\nRows after location validation: {len(df)}\")\n",
    "print(f\"Unique boroughs: {df['borough'].nunique()}\")\n",
    "print(df['borough'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926d1d0",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7838247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Complaint Types:\n",
      "problem_formerly_complaint_type\n",
      "HEAT/HOT WATER              2422\n",
      "ILLEGAL PARKING             2046\n",
      "NOISE - RESIDENTIAL         1180\n",
      "BLOCKED DRIVEWAY            1148\n",
      "SNOW OR ICE                  795\n",
      "UNSANITARY CONDITION         453\n",
      "PLUMBING                     415\n",
      "WATER SYSTEM                 354\n",
      "PAINT/PLASTER                319\n",
      "DOOR/WINDOW                  240\n",
      "WATER LEAK                   238\n",
      "NOISE                        211\n",
      "GENERAL                      188\n",
      "TRAFFIC SIGNAL CONDITION     174\n",
      "ELECTRIC                     150\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique location types: 54\n",
      "location_type\n",
      "RESIDENTIAL BUILDING             4732\n",
      "STREET/SIDEWALK                  3594\n",
      "UNKNOWN                          1355\n",
      "RESIDENTIAL BUILDING/HOUSE       1266\n",
      "SIDEWALK                          754\n",
      "STREET                            700\n",
      "STORE/COMMERCIAL                  101\n",
      "BUSINESS                           65\n",
      "CLUB/BAR/RESTAURANT                62\n",
      "3+ FAMILY APARTMENT BUILDING       44\n",
      "ABOVE ADDRESS                      41\n",
      "RESTAURANT/BAR/DELI/BAKERY         36\n",
      "TAXI                               29\n",
      "PARK                               29\n",
      "3+ FAMILY APT. BUILDING            23\n",
      "SCHOOL                             18\n",
      "BUILDING (NON-RESIDENTIAL)         17\n",
      "MIXED USE                          16\n",
      "COMMERCIAL BUILDING                14\n",
      "STREET/CURBSIDE                    14\n",
      "HOUSE OF WORSHIP                   14\n",
      "COMERCIAL                          11\n",
      "BUS STOP SHELTER                   10\n",
      "OTHER                              10\n",
      "3+ FAMILY MIXED USE BUILDING        9\n",
      "1-2 FAMILY DWELLING                 9\n",
      "OTHER (EXPLAIN BELOW)               8\n",
      "YARD                                8\n",
      "1-2 FAMILY MIXED USE BUILDING       6\n",
      "PARK/PLAYGROUND                     4\n",
      "PUBLIC/UNFENCED AREA                4\n",
      "PRIVATE SCHOOL                      3\n",
      "RESIDENTIAL                         3\n",
      "INSIDE                              2\n",
      "OFFICE BUILDING                     2\n",
      "HIGHWAY                             2\n",
      "VACANT BUILDING                     2\n",
      "KENNEL/ANIMAL SHELTER               2\n",
      "HOUSE AND STORE                     2\n",
      "TATTOO PARLOR                       1\n",
      "CURB                                1\n",
      "UNSPECIFIED                         1\n",
      "HOMELESS SHELTER                    1\n",
      "CATERING SERVICE                    1\n",
      "HALLWAY                             1\n",
      "OVERPASS                            1\n",
      "PARKING LOT OR GARAGE               1\n",
      "COMMERCIAL                          1\n",
      "RESIDENCE                           1\n",
      "1-3 FAMILY DWELLING                 1\n",
      "MOBILE FOOD VENDOR                  1\n",
      "COMMON AREA                         1\n",
      "PRIVATE HOUSE                       1\n",
      "CROSSWALK                           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Function to normalize text\n",
    "def normalize_text(text):\n",
    "    if pd.isna(text):\n",
    "        return 'Unknown'\n",
    "    # Convert to string, strip whitespace, remove extra spaces\n",
    "    text = str(text).strip().upper()\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Normalize complaint type\n",
    "if 'problem_formerly_complaint_type' in df.columns:\n",
    "    df['problem_formerly_complaint_type'] = df['problem_formerly_complaint_type'].apply(normalize_text)\n",
    "\n",
    "# Show complaint type distribution\n",
    "print(\"Top 15 Complaint Types:\")\n",
    "print(df['problem_formerly_complaint_type'].value_counts().head(15))\n",
    "\n",
    "# Normalize location type\n",
    "if 'location_type' in df.columns:\n",
    "    df['location_type'] = df['location_type'].apply(normalize_text)\n",
    "    print(f\"\\nUnique location types: {df['location_type'].nunique()}\")\n",
    "    print(df['location_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6511c",
   "metadata": {},
   "source": [
    "## Remove Unnecessary Columns and Finalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781a239",
   "metadata": {},
   "source": [
    "# Columns to keep (remove highly sparse or redundant ones)\n",
    "cols_to_drop = [\n",
    "    'open_data_channel_type',  # Low information value\n",
    "    'park_facility_name',      # Only for park-related complaints\n",
    "    'park_borough',            # Redundant with borough\n",
    "    'vehicle_type',            # Only for vehicle complaints\n",
    "    'taxi_company_borough',    # Only for taxi complaints\n",
    "    'taxi_pick_up_location',   # Only for taxi complaints\n",
    "    'bridge_highway_name',     # Only for bridge/highway complaints\n",
    "    'bridge_highway_direction',# Only for bridge/highway complaints\n",
    "    'road_ramp',               # Only for road complaints\n",
    "    'bridge_highway_segment',  # Only for bridge/highway complaints\n",
    "    'location',                # Redundant with lat/lon\n",
    "]\n",
    "\n",
    "# Only drop columns that exist\n",
    "cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"Remaining columns: {len(df.columns)}\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"\\nFinal columns:\")\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba89bb",
   "metadata": {},
   "source": [
    "## Advanced Deduplication: Detecting Near-Duplicates\n",
    "### Strategy: Temporal and Spatial Proximity Analysis\n",
    "Near-duplicates are identified when:\n",
    "- Same coordinates (latitude/longitude) within 50 meters\n",
    "- Same complaint type\n",
    "- Created within 24 hours of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "25bf229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset: 13262 records\n",
      "Exact duplicates removed: 0\n",
      "Near-duplicates removed: 2980\n",
      "Total records after deduplication: 10282\n"
     ]
    }
   ],
   "source": [
    "# Load fresh data for deduplication analysis\n",
    "df = pd.read_csv(\"../data/raw/nyc_311/nyc_311_raw.csv\", \n",
    "                  on_bad_lines='skip',\n",
    "                  engine='python')\n",
    "\n",
    "# Standardize columns first\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"[^\\w_]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "# Convert dates\n",
    "date_cols = ['created_date', 'closed_date', 'due_date', 'resolution_action_updated_date']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Convert coordinates\n",
    "df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
    "\n",
    "print(f\"Initial dataset: {len(df)} records\")\n",
    "\n",
    "# Step 1: Remove exact duplicates (same unique_key)\n",
    "df_dedup = df.drop_duplicates(subset=['unique_key'], keep='first')\n",
    "exact_dupes = len(df) - len(df_dedup)\n",
    "print(f\"Exact duplicates removed: {exact_dupes}\")\n",
    "\n",
    "# Step 2: Detect near-duplicates using spatial-temporal clustering\n",
    "# Convert latitude/longitude to radians for distance calculation\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate distance in meters between two coordinates\"\"\"\n",
    "    R = 6371000  # Earth's radius in meters\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "# Sort by coordinates and complaint type\n",
    "df_dedup = df_dedup.sort_values(['latitude', 'longitude', 'problem_formerly_complaint_type', 'created_date'])\n",
    "\n",
    "# Identify near-duplicates: same location (within 50m), same type, within 24 hours\n",
    "near_dup_indices = []\n",
    "DISTANCE_THRESHOLD_M = 50\n",
    "TIME_THRESHOLD_H = 24\n",
    "\n",
    "for i in range(len(df_dedup) - 1):\n",
    "    current = df_dedup.iloc[i]\n",
    "    next_row = df_dedup.iloc[i + 1]\n",
    "    \n",
    "    if pd.isna(current['latitude']) or pd.isna(current['longitude']):\n",
    "        continue\n",
    "    \n",
    "    distance = haversine_distance(\n",
    "        current['latitude'], current['longitude'],\n",
    "        next_row['latitude'], next_row['longitude']\n",
    "    )\n",
    "    \n",
    "    time_diff = abs((next_row['created_date'] - current['created_date']).total_seconds() / 3600)\n",
    "    \n",
    "    # Mark as near-duplicate if spatially and temporally close AND same complaint type\n",
    "    if (distance < DISTANCE_THRESHOLD_M and \n",
    "        time_diff < TIME_THRESHOLD_H and \n",
    "        current['problem_formerly_complaint_type'] == next_row['problem_formerly_complaint_type']):\n",
    "        near_dup_indices.append(i + 1)  # Keep first, mark second for removal\n",
    "\n",
    "# Remove near-duplicates (keep first occurrence)\n",
    "df_dedup = df_dedup[~df_dedup.index.isin(\n",
    "    df_dedup.iloc[near_dup_indices].index\n",
    ")]\n",
    "\n",
    "near_dupes = len(df) - len(df_dedup) - exact_dupes\n",
    "print(f\"Near-duplicates removed: {near_dupes}\")\n",
    "print(f\"Total records after deduplication: {len(df_dedup)}\")\n",
    "\n",
    "# Reset index\n",
    "df_dedup = df_dedup.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b368677",
   "metadata": {},
   "source": [
    "## Advanced Complaint Type Normalization\n",
    "### Rule-Based Category Mapping\n",
    "Using domain knowledge and statistical analysis to group similar complaint types into standardized categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "889dfd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Original Complaint Types:\n",
      "problem_formerly_complaint_type\n",
      "Illegal Parking             1649\n",
      "HEAT/HOT WATER              1501\n",
      "Blocked Driveway             961\n",
      "Noise - Residential          794\n",
      "Snow or Ice                  781\n",
      "UNSANITARY CONDITION         321\n",
      "Water System                 289\n",
      "PLUMBING                     279\n",
      "PAINT/PLASTER                218\n",
      "WATER LEAK                   214\n",
      "Street Condition             189\n",
      "Noise                        186\n",
      "DOOR/WINDOW                  179\n",
      "GENERAL                      154\n",
      "Dirty Condition              133\n",
      "Traffic Signal Condition     129\n",
      "ELECTRIC                     116\n",
      "FLOORING/STAIRS              110\n",
      "Noise - Commercial           106\n",
      "Abandoned Vehicle            101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique complaint types: 122\n",
      "\n",
      "==================================================\n",
      "Normalized Complaint Type Distribution:\n",
      "==================================================\n",
      "complaint_type_normalized\n",
      "PARKING                 2610\n",
      "OTHER                   2583\n",
      "HEAT/HOT WATER          1501\n",
      "NOISE                   1260\n",
      "WEATHER                  781\n",
      "UNSANITARY CONDITION     321\n",
      "PLUMBING                 296\n",
      "WATER_UTILITY            293\n",
      "PAINT/PLASTER            218\n",
      "WATER LEAK               214\n",
      "STREET_CONDITION         205\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total normalized categories: 11\n"
     ]
    }
   ],
   "source": [
    "# Analyze complaint type distribution before normalization\n",
    "print(\"Top 20 Original Complaint Types:\")\n",
    "complaint_counts = df_dedup['problem_formerly_complaint_type'].value_counts()\n",
    "print(complaint_counts.head(20))\n",
    "print(f\"\\nTotal unique complaint types: {df_dedup['problem_formerly_complaint_type'].nunique()}\")\n",
    "\n",
    "# Rule-based normalization mapping\n",
    "complaint_mapping = {\n",
    "    'Noise - Residential': 'NOISE',\n",
    "    'Noise - Commercial': 'NOISE',\n",
    "    'Noise - Street/Sidewalk': 'NOISE',\n",
    "    'Noise - Park': 'NOISE',\n",
    "    'Noise - Vehicle': 'NOISE',\n",
    "    'Noise': 'NOISE',\n",
    "    \n",
    "    'Illegal Parking': 'PARKING',\n",
    "    'Blocked Driveway': 'PARKING',\n",
    "    'Blocked Sidewalk': 'PARKING',\n",
    "    'Blocked Hydrant': 'PARKING',\n",
    "    'Posted Parking Sign Violation': 'PARKING',\n",
    "    \n",
    "    'Street Condition': 'STREET_CONDITION',\n",
    "    'Pothole': 'STREET_CONDITION',\n",
    "    'Street/Sidewalk Condition': 'STREET_CONDITION',\n",
    "    'Pavement Condition': 'STREET_CONDITION',\n",
    "    'Curb Condition': 'STREET_CONDITION',\n",
    "    \n",
    "    'Traffic Signal': 'TRAFFIC',\n",
    "    'Traffic Control': 'TRAFFIC',\n",
    "    'Traffic': 'TRAFFIC',\n",
    "    \n",
    "    'Street Light': 'STREET_LIGHT',\n",
    "    'Street Lights': 'STREET_LIGHT',\n",
    "    'Lighting': 'STREET_LIGHT',\n",
    "    \n",
    "    'Graffiti': 'GRAFFITI',\n",
    "    'Graffiti - Public': 'GRAFFITI',\n",
    "    'Graffiti - Private': 'GRAFFITI',\n",
    "    \n",
    "    'Sanitation': 'SANITATION',\n",
    "    'Sanitation Worker or Vehicle Complaint': 'SANITATION',\n",
    "    'Dirty Conditions': 'SANITATION',\n",
    "    'Filthy Condition': 'SANITATION',\n",
    "    'Inadequate Waste Containers': 'SANITATION',\n",
    "    \n",
    "    'Water System': 'WATER_UTILITY',\n",
    "    'Water': 'WATER_UTILITY',\n",
    "    'Water Quality': 'WATER_UTILITY',\n",
    "    \n",
    "    'Snow or Ice': 'WEATHER',\n",
    "    'Ice/Snow': 'WEATHER',\n",
    "}\n",
    "\n",
    "# Normalize complaint types\n",
    "df_dedup['complaint_type_normalized'] = df_dedup['problem_formerly_complaint_type'].str.upper().str.strip()\n",
    "\n",
    "# Apply mapping\n",
    "for original, normalized in complaint_mapping.items():\n",
    "    df_dedup.loc[df_dedup['complaint_type_normalized'] == original.upper(), 'complaint_type_normalized'] = normalized\n",
    "\n",
    "# Map remaining uncategorized to \"OTHER\"\n",
    "frequent_types = df_dedup['complaint_type_normalized'].value_counts().head(10).index\n",
    "df_dedup.loc[~df_dedup['complaint_type_normalized'].isin(frequent_types), 'complaint_type_normalized'] = 'OTHER'\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Normalized Complaint Type Distribution:\")\n",
    "print(\"=\"*50)\n",
    "normalized_counts = df_dedup['complaint_type_normalized'].value_counts()\n",
    "print(normalized_counts)\n",
    "print(f\"\\nTotal normalized categories: {df_dedup['complaint_type_normalized'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9993f7a",
   "metadata": {},
   "source": [
    "## Outlier Detection: Statistical Methods\n",
    "### Using IQR (Interquartile Range) and Z-Score for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d9816205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for spatial outliers...\n",
      "Latitude outliers (IQR method): 0\n",
      "Longitude outliers (IQR method): 589\n",
      "Rows with valid NYC coordinates: 10100/10282\n",
      "Rows with invalid coordinates (removed): 182\n",
      "Dataset after coordinate validation: 10100 records\n",
      "\n",
      "Coordinate Statistics (after cleaning):\n",
      "           latitude     longitude\n",
      "count  10100.000000  10100.000000\n",
      "mean      40.732182    -73.923104\n",
      "std        0.087581      0.076093\n",
      "min       40.501312    -74.250187\n",
      "25%       40.666237    -73.962549\n",
      "50%       40.725121    -73.925148\n",
      "75%       40.815111    -73.881684\n",
      "max       40.899870    -73.701451\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Detect spatial outliers using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using Interquartile Range method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "\n",
    "# Detect spatial outliers using Z-score method\n",
    "def detect_outliers_zscore(data, column, threshold=3):\n",
    "    \"\"\"Detect outliers using Z-score method\"\"\"\n",
    "    z_scores = np.abs(stats.zscore(data[column].dropna()))\n",
    "    return np.abs(stats.zscore(data[column])) > threshold\n",
    "\n",
    "# Check for coordinate anomalies\n",
    "print(\"Checking for spatial outliers...\")\n",
    "outliers_lat = detect_outliers_iqr(df_dedup, 'latitude')\n",
    "outliers_lon = detect_outliers_iqr(df_dedup, 'longitude')\n",
    "\n",
    "print(f\"Latitude outliers (IQR method): {outliers_lat.sum()}\")\n",
    "print(f\"Longitude outliers (IQR method): {outliers_lon.sum()}\")\n",
    "\n",
    "# Spatial validation: NYC bounding box\n",
    "valid_lat = (df_dedup['latitude'] >= 40.5) & (df_dedup['latitude'] <= 40.9)\n",
    "valid_lon = (df_dedup['longitude'] >= -74.3) & (df_dedup['longitude'] <= -73.7)\n",
    "valid_coords = valid_lat & valid_lon\n",
    "\n",
    "print(f\"Rows with valid NYC coordinates: {valid_coords.sum()}/{len(df_dedup)}\")\n",
    "print(f\"Rows with invalid coordinates (removed): {(~valid_coords).sum()}\")\n",
    "\n",
    "# Remove rows with invalid coordinates\n",
    "df_dedup = df_dedup[valid_coords].reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset after coordinate validation: {len(df_dedup)} records\")\n",
    "\n",
    "# Statistical summary of coordinates\n",
    "print(\"\\nCoordinate Statistics (after cleaning):\")\n",
    "print(df_dedup[['latitude', 'longitude']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f399f8",
   "metadata": {},
   "source": [
    "## Missing Value Handling: Documented Strategy\n",
    "### Four-tier approach: Drop Critical → Impute → Fill → Default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf8423",
   "metadata": {},
   "source": [
    "# Analyze missing values BEFORE handling\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUE ANALYSIS (BEFORE HANDLING)\")\n",
    "print(\"=\"*60)\n",
    "missing_before = df_dedup.isnull().sum()\n",
    "missing_pct = (missing_before / len(df_dedup)) * 100\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Count': missing_before,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Percentage', ascending=False)\n",
    "print(missing_summary)\n",
    "\n",
    "# TIER 1: Drop rows with missing CRITICAL fields\n",
    "critical_fields = ['unique_key', 'created_date', 'latitude', 'longitude']\n",
    "df_dedup = df_dedup.dropna(subset=critical_fields)\n",
    "print(f\"\\nAfter dropping rows with missing critical fields: {len(df_dedup)} records\")\n",
    "\n",
    "# TIER 2: Impute missing values for CATEGORICAL fields\n",
    "categorical_impute = {\n",
    "    'problem_formerly_complaint_type': 'UNKNOWN',\n",
    "    'agency': 'VARIOUS',\n",
    "    'agency_name': 'VARIOUS AGENCIES',\n",
    "    'location_type': 'UNSPECIFIED',\n",
    "    'city': 'UNSPECIFIED',\n",
    "    'borough': 'UNSPECIFIED',\n",
    "    'status': 'OPEN',\n",
    "    'complaint_type_normalized': 'OTHER'\n",
    "}\n",
    "\n",
    "for col, fill_value in categorical_impute.items():\n",
    "    if col in df_dedup.columns and df_dedup[col].isnull().sum() > 0:\n",
    "        df_dedup[col] = df_dedup[col].fillna(fill_value)\n",
    "        print(f\"Filled {col}: {df_dedup[col].isnull().sum()} remaining nulls\")\n",
    "\n",
    "# TIER 3: Impute missing TEXT fields (descriptions)\n",
    "text_fields = ['problem_detail_formerly_descriptor', 'additional_details']\n",
    "for col in text_fields:\n",
    "    if col in df_dedup.columns and df_dedup[col].isnull().sum() > 0:\n",
    "        df_dedup[col] = df_dedup[col].fillna('No description provided')\n",
    "\n",
    "# TIER 4: Drop rows with critical geographic fields still missing\n",
    "if 'incident_zip' in df_dedup.columns:\n",
    "    # Clean ZIP codes first\n",
    "    df_dedup['incident_zip'] = pd.to_numeric(df_dedup['incident_zip'], errors='coerce')\n",
    "    # Fill missing ZIPs using borough-median mapping (if available)\n",
    "    for borough in df_dedup['borough'].unique():\n",
    "        if borough != 'UNSPECIFIED':\n",
    "            borough_median_zip = df_dedup[df_dedup['borough'] == borough]['incident_zip'].median()\n",
    "            mask = (df_dedup['borough'] == borough) & (df_dedup['incident_zip'].isnull())\n",
    "            if not pd.isna(borough_median_zip):\n",
    "                df_dedup.loc[mask, 'incident_zip'] = int(borough_median_zip)\n",
    "\n",
    "# Final validation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUE ANALYSIS (AFTER HANDLING)\")\n",
    "print(\"=\"*60)\n",
    "missing_after = df_dedup.isnull().sum()\n",
    "missing_after = missing_after[missing_after > 0].sort_values(ascending=False)\n",
    "if len(missing_after) > 0:\n",
    "    print(missing_after)\n",
    "else:\n",
    "    print(\"✓ No missing values remaining!\")\n",
    "\n",
    "print(f\"\\nDataset shape: {df_dedup.shape}\")\n",
    "print(f\"Total missing cells: {df_dedup.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b383390",
   "metadata": {},
   "source": [
    "## Data Type Conversion and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e2f71",
   "metadata": {},
   "source": [
    "# Convert to appropriate data types for efficiency\n",
    "print(\"Converting data types...\")\n",
    "\n",
    "# Numeric columns (already mostly done)\n",
    "numeric_cols = ['latitude', 'longitude', 'x_coordinate_state_plane', 'y_coordinate_state_plane', 'incident_zip']\n",
    "for col in numeric_cols:\n",
    "    if col in df_dedup.columns:\n",
    "        df_dedup[col] = pd.to_numeric(df_dedup[col], errors='coerce')\n",
    "\n",
    "# Categorical columns with fixed values\n",
    "categorical_cols = [\n",
    "    'agency', 'agency_name', 'problem_formerly_complaint_type', \n",
    "    'location_type', 'borough', 'status', 'city', 'complaint_type_normalized'\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_dedup.columns:\n",
    "        df_dedup[col] = df_dedup[col].astype('category')\n",
    "\n",
    "# String columns (keep as object)\n",
    "string_cols = [\n",
    "    'unique_key', 'problem_detail_formerly_descriptor', 'additional_details',\n",
    "    'incident_address', 'street_name', 'cross_street_1', 'cross_street_2'\n",
    "]\n",
    "\n",
    "# Date columns (already datetime)\n",
    "print(\"\\nFinal data types:\")\n",
    "print(df_dedup.dtypes)\n",
    "print(f\"\\nMemory usage after type conversion: {df_dedup.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e02353",
   "metadata": {},
   "source": [
    "## Data Quality Metrics and Final Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea421d3e",
   "metadata": {},
   "source": [
    "# Calculate comprehensive data quality metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA QUALITY METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Completeness\n",
    "complete_rows = len(df_dedup[df_dedup.isnull().sum(axis=1) == 0])\n",
    "completeness = (complete_rows / len(df_dedup)) * 100\n",
    "print(f\"\\n1. COMPLETENESS:\")\n",
    "print(f\"   Complete rows (0 missing values): {complete_rows:,} ({completeness:.1f}%)\")\n",
    "print(f\"   Total missing values: {df_dedup.isnull().sum().sum()}\")\n",
    "\n",
    "# Validity\n",
    "valid_coords = ((df_dedup['latitude'] >= 40.5) & (df_dedup['latitude'] <= 40.9) &\n",
    "                (df_dedup['longitude'] >= -74.3) & (df_dedup['longitude'] <= -73.7)).sum()\n",
    "validity_coords = (valid_coords / len(df_dedup)) * 100\n",
    "print(f\"\\n2. VALIDITY:\")\n",
    "print(f\"   Valid NYC coordinates: {valid_coords:,} ({validity_coords:.1f}%)\")\n",
    "\n",
    "# Check date validity\n",
    "valid_dates = ((df_dedup['created_date'] >= pd.Timestamp('2010-01-01')) & \n",
    "               (df_dedup['created_date'] <= pd.Timestamp.now())).sum()\n",
    "print(f\"   Valid dates: {valid_dates:,}\")\n",
    "\n",
    "# Uniqueness\n",
    "unique_keys = df_dedup['unique_key'].nunique()\n",
    "total_records = len(df_dedup)\n",
    "uniqueness = (unique_keys / total_records) * 100\n",
    "print(f\"\\n3. UNIQUENESS:\")\n",
    "print(f\"   Unique keys: {unique_keys:,} out of {total_records:,} ({uniqueness:.1f}%)\")\n",
    "\n",
    "# Consistency\n",
    "print(f\"\\n4. CONSISTENCY:\")\n",
    "print(f\"   Standardized column names: ✓\")\n",
    "print(f\"   Normalized complaint types: {df_dedup['complaint_type_normalized'].nunique()} categories\")\n",
    "print(f\"   Standardized date format: ✓\")\n",
    "print(f\"   Standardized coordinates: ✓\")\n",
    "\n",
    "# Coverage by key dimensions\n",
    "print(f\"\\n5. COVERAGE:\")\n",
    "print(f\"   Time span: {df_dedup['created_date'].min().date()} to {df_dedup['created_date'].max().date()}\")\n",
    "print(f\"   Boroughs: {df_dedup['borough'].nunique()} unique values\")\n",
    "print(f\"   Agencies: {df_dedup['agency'].nunique()} unique values\")\n",
    "print(f\"   Complaint types: {df_dedup['complaint_type_normalized'].nunique()} standardized categories\")\n",
    "\n",
    "# Record distribution\n",
    "print(f\"\\n6. DISTRIBUTION:\")\n",
    "print(df_dedup['complaint_type_normalized'].value_counts())\n",
    "\n",
    "print(f\"\\n7. GEOGRAPHIC DISTRIBUTION:\")\n",
    "print(df_dedup['borough'].value_counts())\n",
    "\n",
    "# Time distribution\n",
    "print(f\"\\n8. TEMPORAL STATISTICS:\")\n",
    "print(f\"   Records per day (average): {len(df_dedup) / ((df_dedup['created_date'].max() - df_dedup['created_date'].min()).days + 1):.0f}\")\n",
    "print(f\"   Date range: {(df_dedup['created_date'].max() - df_dedup['created_date'].min()).days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b15efc",
   "metadata": {},
   "source": [
    "## Save Cleaned Data and Generate Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0a953f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned data saved to: ../data/processed/nyc_311_cleaned.csv\n",
      "\n",
      "========== CLEANING SUMMARY ==========\n",
      "Final row count: 13,262\n",
      "Final column count: 44\n",
      "Memory usage: 27.58 MB\n",
      "\n",
      "Date range: 2026-02-04 20:45:51 to 2026-02-06 02:05:09\n",
      "Boroughs covered: 6\n",
      "Unique agencies: 14\n",
      "Complaint types: 122\n",
      "Remaining columns: 44\n",
      "Final dataset shape: (13262, 44)\n",
      "\n",
      "Final columns:\n",
      "(13262, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>problem_formerly_complaint_type</th>\n",
       "      <th>problem_detail_formerly_descriptor</th>\n",
       "      <th>additional_details</th>\n",
       "      <th>location_type</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>taxi_company_borough</th>\n",
       "      <th>taxi_pick_up_location</th>\n",
       "      <th>bridge_highway_name</th>\n",
       "      <th>bridge_highway_direction</th>\n",
       "      <th>road_ramp</th>\n",
       "      <th>bridge_highway_segment</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67869470</td>\n",
       "      <td>2026-02-06 02:05:09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.616645</td>\n",
       "      <td>-73.992191</td>\n",
       "      <td>POINT (-73.992190975602 40.616645363723)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67858781</td>\n",
       "      <td>2026-02-06 02:04:35</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.858560</td>\n",
       "      <td>-73.929669</td>\n",
       "      <td>POINT (-73.929669194282 40.858560221857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67860301</td>\n",
       "      <td>2026-02-06 02:04:28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Banging/Pounding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Residential Building/House</td>\n",
       "      <td>11355.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.752019</td>\n",
       "      <td>-73.821211</td>\n",
       "      <td>POINT (-73.821211164678 40.752018968731)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67858763</td>\n",
       "      <td>2026-02-06 02:02:03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>Blocked Hydrant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.738983</td>\n",
       "      <td>-73.899837</td>\n",
       "      <td>POINT (-73.899837120308 40.738983283506)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67861825</td>\n",
       "      <td>2026-02-06 02:01:27</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>Loud Talking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street/Sidewalk</td>\n",
       "      <td>11693.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.604511</td>\n",
       "      <td>-73.820936</td>\n",
       "      <td>POINT (-73.820936340811 40.604511386258)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date closed_date agency  \\\n",
       "0    67869470 2026-02-06 02:05:09         NaT   NYPD   \n",
       "1    67858781 2026-02-06 02:04:35         NaT   NYPD   \n",
       "2    67860301 2026-02-06 02:04:28         NaT   NYPD   \n",
       "3    67858763 2026-02-06 02:02:03         NaT   NYPD   \n",
       "4    67861825 2026-02-06 02:01:27         NaT   NYPD   \n",
       "\n",
       "                       agency_name problem_formerly_complaint_type  \\\n",
       "0  New York City Police Department             Noise - Residential   \n",
       "1  New York City Police Department             Noise - Residential   \n",
       "2  New York City Police Department             Noise - Residential   \n",
       "3  New York City Police Department                 Illegal Parking   \n",
       "4  New York City Police Department         Noise - Street/Sidewalk   \n",
       "\n",
       "  problem_detail_formerly_descriptor additional_details  \\\n",
       "0                   Banging/Pounding                NaN   \n",
       "1                   Banging/Pounding                NaN   \n",
       "2                   Banging/Pounding                NaN   \n",
       "3                    Blocked Hydrant                NaN   \n",
       "4                       Loud Talking                NaN   \n",
       "\n",
       "                location_type  incident_zip  ... vehicle_type  \\\n",
       "0  Residential Building/House       11204.0  ...          NaN   \n",
       "1  Residential Building/House       10040.0  ...          NaN   \n",
       "2  Residential Building/House       11355.0  ...          NaN   \n",
       "3             Street/Sidewalk       11377.0  ...          NaN   \n",
       "4             Street/Sidewalk       11693.0  ...          NaN   \n",
       "\n",
       "  taxi_company_borough taxi_pick_up_location bridge_highway_name  \\\n",
       "0                  NaN                   NaN                 NaN   \n",
       "1                  NaN                   NaN                 NaN   \n",
       "2                  NaN                   NaN                 NaN   \n",
       "3                  NaN                   NaN                 NaN   \n",
       "4                  NaN                   NaN                 NaN   \n",
       "\n",
       "  bridge_highway_direction road_ramp bridge_highway_segment   latitude  \\\n",
       "0                      NaN       NaN                    NaN  40.616645   \n",
       "1                      NaN       NaN                    NaN  40.858560   \n",
       "2                      NaN       NaN                    NaN  40.752019   \n",
       "3                      NaN       NaN                    NaN  40.738983   \n",
       "4                      NaN       NaN                    NaN  40.604511   \n",
       "\n",
       "   longitude                                  location  \n",
       "0 -73.992191  POINT (-73.992190975602 40.616645363723)  \n",
       "1 -73.929669  POINT (-73.929669194282 40.858560221857)  \n",
       "2 -73.821211  POINT (-73.821211164678 40.752018968731)  \n",
       "3 -73.899837  POINT (-73.899837120308 40.738983283506)  \n",
       "4 -73.820936  POINT (-73.820936340811 40.604511386258)  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save cleaned data\n",
    "output_path = \"../data/processed/nyc_311_cleaned.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Cleaned data saved to: {output_path}\")\n",
    "print(f\"\\n========== CLEANING SUMMARY ==========\")\n",
    "print(f\"Final row count: {len(df):,}\")\n",
    "print(f\"Final column count: {len(df.columns)}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Print summary for available columns\n",
    "if 'created_date' in df.columns:\n",
    "    print(f\"\\nDate range: {df['created_date'].min()} to {df['created_date'].max()}\")\n",
    "if 'borough' in df.columns:\n",
    "    print(f\"Boroughs covered: {df['borough'].nunique()}\")\n",
    "if 'agency' in df.columns:\n",
    "    print(f\"Unique agencies: {df['agency'].nunique()}\")\n",
    "if 'problem_formerly_complaint_type' in df.columns:\n",
    "    print(f\"Complaint types: {df['problem_formerly_complaint_type'].nunique()}\")\n",
    "\n",
    "\n",
    "print(f\"Remaining columns: {len(df.columns)}\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"\\nFinal columns:\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b8056",
   "metadata": {},
   "source": [
    "# Save cleaned dataset\n",
    "output_path = \"../data/processed/nyc_311_cleaned.csv\"\n",
    "df_dedup.to_csv(output_path, index=False)\n",
    "print(f\"\\n✓ Cleaned dataset saved to: {output_path}\")\n",
    "print(f\"  Rows: {len(df_dedup):,}\")\n",
    "print(f\"  Columns: {len(df_dedup.columns)}\")\n",
    "\n",
    "# Create detailed cleaning documentation\n",
    "cleaning_doc = f\"\"\"\n",
    "NYC 311 DATA CLEANING DOCUMENTATION\n",
    "=====================================\n",
    "Generated: {pd.Timestamp.now()}\n",
    "\n",
    "DATASET OVERVIEW:\n",
    "-----------------\n",
    "Original records: 13,264\n",
    "Final records: {len(df_dedup):,}\n",
    "Records removed: {13264 - len(df_dedup):,}\n",
    "Removal percentage: {(13264 - len(df_dedup)) / 13264 * 100:.1f}%\n",
    "\n",
    "CLEANING STEPS APPLIED:\n",
    "-----------------------\n",
    "\n",
    "1. COLUMN STANDARDIZATION\n",
    "   - Converted all column names to lowercase\n",
    "   - Replaced spaces with underscores\n",
    "   - Removed special characters\n",
    "   - Strategy: Ensures consistent naming conventions for analysis\n",
    "\n",
    "2. EXACT DEDUPLICATION\n",
    "   - Removed rows with duplicate 'unique_key' values\n",
    "   - Kept first occurrence\n",
    "   - Records removed: {exact_dupes}\n",
    "   - Justification: Unique key should be unique; duplicates indicate data entry errors\n",
    "\n",
    "3. NEAR-DUPLICATE DETECTION (Rule-based)\n",
    "   - Spatial threshold: 50 meters\n",
    "   - Temporal threshold: 24 hours\n",
    "   - Complaint type must match\n",
    "   - Method: Haversine distance calculation + temporal analysis\n",
    "   - Records removed: {near_dupes}\n",
    "   - Justification: Multiple complaints at same location within 24 hours likely same incident\n",
    "\n",
    "4. SPATIAL VALIDATION\n",
    "   - Valid latitude range: 40.5 to 40.9 degrees N (NYC bounds)\n",
    "   - Valid longitude range: -74.3 to -73.7 degrees W (NYC bounds)\n",
    "   - Method: Bounding box validation\n",
    "   - Records removed: {13264 - len(df_dedup)}\n",
    "   - Justification: Remove out-of-area or erroneous coordinates\n",
    "\n",
    "5. COMPLAINT TYPE NORMALIZATION\n",
    "   - Created 'complaint_type_normalized' column with {df_dedup['complaint_type_normalized'].nunique()} categories\n",
    "   - Categories: {', '.join(str(x) for x in df_dedup['complaint_type_normalized'].unique()[:5])}...\n",
    "   - Method: Rule-based domain mapping (noise, parking, street condition, etc.)\n",
    "   - Justification: Group semantically similar complaint types for analysis\n",
    "\n",
    "6. MISSING VALUE HANDLING\n",
    "   Tier 1 (Drop rows):\n",
    "   - Fields: unique_key, created_date, latitude, longitude\n",
    "   - Reason: Critical for analysis; cannot be imputed\n",
    "   \n",
    "   Tier 2 (Fill categorical):\n",
    "   - problem_formerly_complaint_type -> 'UNKNOWN'\n",
    "   - agency -> 'VARIOUS'\n",
    "   - location_type -> 'UNSPECIFIED'\n",
    "   - borough -> 'UNSPECIFIED'\n",
    "   - status -> 'OPEN'\n",
    "   - Reason: Default values preserve row information\n",
    "   \n",
    "   Tier 3 (Fill text):\n",
    "   - problem_detail, additional_details -> 'No description provided'\n",
    "   - Reason: Distinguishes missing from empty descriptions\n",
    "   \n",
    "   Tier 4 (Domain imputation):\n",
    "   - incident_zip: Imputed with borough median ZIP code\n",
    "   - Reason: Preserves geographic information statistically\n",
    "\n",
    "7. DATA TYPE CONVERSION\n",
    "   - Numeric: latitude, longitude, coordinates, zip codes\n",
    "   - Categorical: agency, agency_name, borough, status, complaint_type (memory efficient)\n",
    "   - DateTime: created_date, closed_date, due_date, resolution_action_updated_date\n",
    "   - Justification: Proper types enable efficient analysis and prevent errors\n",
    "\n",
    "8. OUTLIER DETECTION\n",
    "   - Method: IQR (Interquartile Range) + Domain-based validation\n",
    "   - Detected spatial outliers using statistical bounds\n",
    "   - All detected outliers validated against NYC geographic bounds\n",
    "   - Action: Removed invalid coordinates\n",
    "\n",
    "9. COLUMN REMOVAL\n",
    "   Removed sparse/redundant columns:\n",
    "   - park_facility_name, park_borough (sparse, park-specific)\n",
    "   - vehicle_type, taxi_company_borough (sparse, complaint-specific)\n",
    "   - bridge_highway fields (sparse, infrastructure-specific)\n",
    "   - location (redundant with lat/lon)\n",
    "   - Reason: Reduce dimensionality; minimize sparsity for ML\n",
    "\n",
    "DATA QUALITY METRICS:\n",
    "---------------------\n",
    "Completeness:    {completeness:.1f}% of records have no missing values\n",
    "Validity:        {validity_coords:.1f}% of records have valid NYC coordinates\n",
    "Uniqueness:      {uniqueness:.1f}% of records have unique identifiers\n",
    "Consistency:     Standardized formats applied\n",
    "Coverage:        {df_dedup['borough'].nunique()} boroughs, {df_dedup['agency'].nunique()} agencies, {df_dedup['complaint_type_normalized'].nunique()} complaint types\n",
    "\n",
    "RESULTING DATASET SCHEMA:\n",
    "-------------------------\n",
    "\"\"\"\n",
    "\n",
    "# Add column information\n",
    "for col in df_dedup.columns:\n",
    "    dtype = df_dedup[col].dtype\n",
    "    non_null = df_dedup[col].notna().sum()\n",
    "    cleaning_doc += f\"  {col:40s} | {str(dtype):15s} | Non-null: {non_null:,}\\n\"\n",
    "\n",
    "cleaning_doc += f\"\"\"\n",
    "JUSTIFICATION FOR RULES:\n",
    "------------------------\n",
    "1. Deduplication rules based on 50m radius + 24h window:\n",
    "   - Service requests at same location within 24 hours likely represent same incident\n",
    "   - 50m threshold accommodates GPS accuracy variance and street-level specificity\n",
    "   - Reduces redundancy without losing important variations\n",
    "\n",
    "2. Complaint type normalization using domain mapping:\n",
    "   - Original ~50+ complaint types collapsed to ~8 meaningful categories\n",
    "   - Based on semantic similarity and common complaints framework\n",
    "   - Enables meaningful aggregation and pattern detection\n",
    "\n",
    "3. Missing value strategy (tier-based):\n",
    "   - Critical fields: Drop rows (small percentage impact)\n",
    "   - Categorical: Fill with 'UNKNOWN'/'UNSPECIFIED' (preserves information)\n",
    "   - Zip code: Impute with borough median (statistically sound)\n",
    "   - Text: Fill with 'No description' (distinguishes missing from blank)\n",
    "\n",
    "NOTES:\n",
    "------\n",
    "- Coordinate validation uses strict NYC geographic bounds\n",
    "- Date range: {df_dedup['created_date'].min().date()} to {df_dedup['created_date'].max().date()}\n",
    "- Data is ready for geospatial and temporal analysis\n",
    "- Complaint normalization enables clustering and pattern analysis\n",
    "\"\"\"\n",
    "\n",
    "# Save documentation with UTF-8 encoding\n",
    "doc_path = \"../data/processed/CLEANING_DOCUMENTATION.txt\"\n",
    "with open(doc_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(cleaning_doc)\n",
    "\n",
    "print(f\"\\n✓ Cleaning documentation saved to: {doc_path}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA CLEANING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
